{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMP7ESG7I0vA"
   },
   "source": [
    "# Detecting Issues in Tabular DataÂ (Numeric/Categorical columns) with Datalab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRNT4ypbI0vB"
   },
   "source": [
    "In this 5-minute quickstart tutorial, we use Datalab to detect various issues in a classification dataset with tabular (numeric/categorical) features. Tabular (or *structured*) data are typically organized in a row/column format and stored in a SQL database or file types like: CSV, Excel, or Parquet. Here we consider a Student Grades dataset, which contains over 900 individuals who have three exam grades and some optional notes, each being assigned a letter grade (their class label). cleanlab automatically identifies _hundreds_ of examples in this dataset that were mislabeled with the incorrect final grade selected. You can run the same code from this tutorial to detect incorrect information in your own tabular classification datasets.\n",
    "\n",
    "**Overview of what we'll do in this tutorial:**\n",
    "\n",
    "- Train a classifier model (here scikit-learn's HistGradientBoostingClassifier, although any model could be used) and use this classifier to compute (out-of-sample) predicted class probabilities via cross-validation.\n",
    "\n",
    "- Create a K nearest neighbours (KNN) graph between the examples in the dataset.\n",
    "\n",
    "- Identify issues in the dataset with cleanlab's `Datalab` audit applied to the predictions and KNN graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:14.545038Z",
     "iopub.status.busy": "2024-09-26T16:53:14.544417Z",
     "iopub.status.idle": "2024-09-26T16:53:14.562811Z",
     "shell.execute_reply": "2024-09-26T16:53:14.562223Z"
    },
    "id": "owzMda4TI0vF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tawfi\\anaconda3\\envs\\nlpenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from cleanlab import Datalab\n",
    "\n",
    "SEED = 100  # for reproducibility\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAhGJ7trI0vG"
   },
   "source": [
    "## 2. Load and process the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g88sGTCQI0vH"
   },
   "source": [
    "We first load the data features and labels (which are possibly noisy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:14.564899Z",
     "iopub.status.busy": "2024-09-26T16:53:14.564451Z",
     "iopub.status.idle": "2024-09-26T16:53:14.606560Z",
     "shell.execute_reply": "2024-09-26T16:53:14.606012Z"
    },
    "id": "hAQCfjqCI0vH",
    "outputId": "b1081a31-3a8c-461a-9520-930cd11f3a42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stud_ID</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>letter_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f48f73</td>\n",
       "      <td>53.00</td>\n",
       "      <td>77.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0bd4e7</td>\n",
       "      <td>81.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>great participation +10</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0bd4e7</td>\n",
       "      <td>81.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>great participation +10</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cb9d7a</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9acca4</td>\n",
       "      <td>48.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stud_ID  exam_1  exam_2  exam_3                    notes letter_grade\n",
       "0  f48f73   53.00   77.00    9.00                        3            C\n",
       "1  0bd4e7   81.00   64.00   80.00  great participation +10            B\n",
       "2  0bd4e7   81.00   64.00   80.00  great participation +10            B\n",
       "3  cb9d7a    0.61    0.94    0.78                      NaN            C\n",
       "4  9acca4   48.00   90.00    9.00                        1            C"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_data = pd.read_csv(\"grades.csv\")\n",
    "grades_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(941, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "   stud_ID  exam_1  exam_2  exam_3                    notes letter_grade\n",
      "2   0bd4e7    81.0    64.0    80.0  great participation +10            B\n",
      "6   0bd4e7    81.0    64.0    80.0  great participation +10            B\n",
      "9   0bd4e7    81.0    64.0    80.0  great participation +10            B\n",
      "12  0bd4e7    81.0    64.0    80.0  great participation +10            B\n"
     ]
    }
   ],
   "source": [
    "print(sum(grades_data.duplicated()))\n",
    "\n",
    "#print duplicate rows\n",
    "print(grades_data[grades_data.duplicated()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:14.608335Z",
     "iopub.status.busy": "2024-09-26T16:53:14.607988Z",
     "iopub.status.idle": "2024-09-26T16:53:14.611501Z",
     "shell.execute_reply": "2024-09-26T16:53:14.611020Z"
    },
    "id": "aDs7iBvEI0vI"
   },
   "outputs": [],
   "source": [
    "X_raw = grades_data[[\"exam_1\", \"exam_2\", \"exam_3\", \"notes\"]]\n",
    "labels = grades_data[\"letter_grade\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_9rwW2CI0vI"
   },
   "source": [
    "Next we preprocess the data. Here we apply one-hot encoding to columns with categorical values and standardize the values in numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:14.613304Z",
     "iopub.status.busy": "2024-09-26T16:53:14.612900Z",
     "iopub.status.idle": "2024-09-26T16:53:14.621059Z",
     "shell.execute_reply": "2024-09-26T16:53:14.620614Z"
    },
    "id": "Qr1LfYT8I0vI"
   },
   "outputs": [],
   "source": [
    "cat_features = [\"notes\"]\n",
    "X_encoded = pd.get_dummies(X_raw, columns=cat_features, drop_first=True)\n",
    "\n",
    "numeric_features = [\"exam_1\", \"exam_2\", \"exam_3\"]\n",
    "scaler = StandardScaler()\n",
    "X_processed = X_encoded.copy()\n",
    "X_processed[numeric_features] = scaler.fit_transform(X_encoded[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_fW5izwI0vJ"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Bringing Your Own Data (BYOD)?\n",
    "\n",
    "Assign your data's features to variable `X` and its labels to variable `labels` instead.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BATMZqFI0vJ"
   },
   "source": [
    "## 3. Select a classification model and compute out-of-sample predicted probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4m1tbq1NI0vJ"
   },
   "source": [
    "Here we use a simple histogram-based gradient boosting model (similar to XGBoost), but you can choose any suitable scikit-learn model for this tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:14.622820Z",
     "iopub.status.busy": "2024-09-26T16:53:14.622534Z",
     "iopub.status.idle": "2024-09-26T16:53:14.625064Z",
     "shell.execute_reply": "2024-09-26T16:53:14.624596Z"
    },
    "id": "8aPxWZsZI0vJ"
   },
   "outputs": [],
   "source": [
    "clf = HistGradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvRuYoLAI0vJ"
   },
   "source": [
    "To find potential labeling errors, cleanlab requires a probabilistic prediction from your model for every datapoint. However, these predictions will be _overfitted_ (and thus unreliable) for examples the model was previously trained on. For the best results, cleanlab should be applied with **out-of-sample** predicted class probabilities, i.e., on examples held out from the model during the training.\n",
    "\n",
    "K-fold cross-validation is a straightforward way to produce out-of-sample predicted probabilities for every datapoint in the dataset by training K copies of our model on different data subsets and using each copy to predict on the subset of data it did not see during training. Make sure that the columns of your `pred_probs` are properly ordered with respect to the ordering of classes, which for Datalab is: lexicographically sorted by class name.\n",
    "We can implement this via the `cross_val_predict` method from scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:14.626698Z",
     "iopub.status.busy": "2024-09-26T16:53:14.626363Z",
     "iopub.status.idle": "2024-09-26T16:53:17.701499Z",
     "shell.execute_reply": "2024-09-26T16:53:17.700847Z"
    },
    "id": "FI2_PWi9I0vJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tawfi\\anaconda3\\envs\\nlpenv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\tawfi\\anaconda3\\envs\\nlpenv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    }
   ],
   "source": [
    "num_crossval_folds = 5\n",
    "pred_probs = cross_val_predict(\n",
    "    clf,\n",
    "    X_processed,\n",
    "    labels,\n",
    "    cv=num_crossval_folds,\n",
    "    method=\"predict_proba\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etTdQJzsI0vK"
   },
   "source": [
    "## 4. Construct K nearest neighbours graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8rZuzoJI0vK"
   },
   "source": [
    "The KNN graph reflects how close each example is when compared to other examples in our dataset (in the numerical space of preprocessed feature values). This similarity information is used by Datalab to identify issues like outliers in our data. For tabular data, think carefully about the most appropriate way to define the similarity between two examples.\n",
    "\n",
    "Here we use the `NearestNeighbors` class in sklearn to easily compute this graph (with similarity defined by the Euclidean distance between feature values). The graph should be represented as a sparse matrix with nonzero entries indicating nearest neighbors of each example and their distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:17.704226Z",
     "iopub.status.busy": "2024-09-26T16:53:17.703617Z",
     "iopub.status.idle": "2024-09-26T16:53:17.713753Z",
     "shell.execute_reply": "2024-09-26T16:53:17.713165Z"
    },
    "id": "2qQj5WY8I0vK"
   },
   "outputs": [],
   "source": [
    "KNN = NearestNeighbors(metric='euclidean')\n",
    "KNN.fit(X_processed.values)\n",
    "\n",
    "knn_graph = KNN.kneighbors_graph(mode=\"distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OipR-HOLI0vK"
   },
   "source": [
    "## 5. Use cleanlab to find label issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lqcMBK6I0vK"
   },
   "source": [
    "Based on the given labels, predicted probabilities, and KNN graph, cleanlab can quickly help us identify suspicious values in our grades table.\n",
    "\n",
    "We use cleanlab's `Datalab` class which has several ways of loading the data. In this case, weâll simply wrap the dataset (features and noisy labels) in a dictionary that is used instantiate a `Datalab` objectÂ such that it can audit our dataset for various types of issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:17.715485Z",
     "iopub.status.busy": "2024-09-26T16:53:17.715302Z",
     "iopub.status.idle": "2024-09-26T16:53:19.768600Z",
     "shell.execute_reply": "2024-09-26T16:53:19.767999Z"
    },
    "id": "2aettQoQI0vK",
    "outputId": "33613480-e161-4037-9add-e08d1bc27589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding label issues ...\n",
      "Finding outlier issues ...\n",
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "Error in non_iid: If a knn_graph is not provided, features must be provided to fit a new knn.\n",
      "Failed to check for these issue types: [NonIIDIssueManager]\n",
      "\n",
      "Audit complete. 357 issues found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "data = {\"X\": X_processed.values, \"y\": labels}\n",
    "\n",
    "lab = Datalab(data, label_name=\"y\")\n",
    "lab.find_issues(pred_probs=pred_probs, knn_graph=knn_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:19.770774Z",
     "iopub.status.busy": "2024-09-26T16:53:19.770344Z",
     "iopub.status.idle": "2024-09-26T16:53:19.790523Z",
     "shell.execute_reply": "2024-09-26T16:53:19.789956Z"
    },
    "id": "US45XP7LI0vL",
    "outputId": "db3de3a8-186a-4dab-e41a-16f812334bac",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information: num_examples: 941, num_classes: 5\n",
      "\n",
      "Here is a summary of various issues found in your data:\n",
      "\n",
      "    issue_type  num_issues\n",
      "         label         294\n",
      "       outlier          46\n",
      "near_duplicate          17\n",
      "       non_iid           1\n",
      "\n",
      "Learn about each issue: https://docs.cleanlab.ai/stable/cleanlab/datalab/guide/issue_type_description.html\n",
      "See which examples in your dataset exhibit each issue via: `datalab.get_issues(<ISSUE_NAME>)`\n",
      "\n",
      "Data indices corresponding to top examples of each issue are shown below.\n",
      "\n",
      "\n",
      "----------------------- label issues -----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples whose given label is estimated to be potentially incorrect\n",
      "    (e.g. due to annotation error) are flagged as having label issues.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 294\n",
      "Overall dataset quality in terms of this issue: 0.7109\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_label_issue  label_score given_label predicted_label\n",
      "3              True     0.000005           C               F\n",
      "886            True     0.000059           D               B\n",
      "709            True     0.000104           F               C\n",
      "723            True     0.000169           A               C\n",
      "689            True     0.000181           B               D\n",
      "\n",
      "\n",
      "---------------------- outlier issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples that are very different from the rest of the dataset \n",
      "    (i.e. potentially out-of-distribution or rare/anomalous instances).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 46\n",
      "Overall dataset quality in terms of this issue: 0.3590\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "   is_outlier_issue  outlier_score\n",
      "3              True   3.051882e-07\n",
      "7              True   7.683133e-05\n",
      "0              True   6.536582e-04\n",
      "4              True   8.406589e-04\n",
      "8              True   5.324246e-03\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 17\n",
      "Overall dataset quality in terms of this issue: 0.6165\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor\n",
      "12                      True                   0.0        [2, 1, 6, 9]                           0.0\n",
      "582                     True                   0.0               [185]                           0.0\n",
      "185                     True                   0.0               [582]                           0.0\n",
      "187                     True                   0.0                [27]                           0.0\n",
      "898                     True                   0.0               [637]                           0.0\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 1\n",
      "Overall dataset quality in terms of this issue: 0.0000\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_non_iid_issue  non_iid_score\n",
      "865              True       0.515002\n",
      "837             False       0.556480\n",
      "622             False       0.593068\n",
      "329             False       0.593207\n",
      "920             False       0.618041\n",
      "\n",
      "Additional Information: \n",
      "p-value: 1.4386345844794593e-05\n"
     ]
    }
   ],
   "source": [
    "lab.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnVBJAlQI0vL"
   },
   "source": [
    "### Label issues\n",
    "\n",
    "The above report shows that cleanlab identified many label issues in the data. We can see which examples are estimated to be mislabeled (as well as a numeric quality score quantifying how likely their label is correct) via the `get_issues` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:19.792434Z",
     "iopub.status.busy": "2024-09-26T16:53:19.792237Z",
     "iopub.status.idle": "2024-09-26T16:53:19.800752Z",
     "shell.execute_reply": "2024-09-26T16:53:19.800195Z"
    },
    "id": "1OT7LWinI0vL",
    "outputId": "0305d2ca-d0ec-43b5-c554-ce58dec36478"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>label_score</th>\n",
       "      <th>given_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.555944</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.555944</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_label_issue  label_score given_label predicted_label\n",
       "0            True     0.000842           C               F\n",
       "1           False     0.555944           B               B\n",
       "2           False     0.555944           B               B\n",
       "3            True     0.000005           C               F\n",
       "4            True     0.004374           C               D"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_results = lab.get_issues(\"label\")\n",
    "issue_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra-9FC96I0vM"
   },
   "source": [
    "To review the most severe label issues, sort the DataFrame above by the `label_score` column (a lower score represents that the label is less likely to be correct).\n",
    "\n",
    "Let's review some of the most likely label errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:19.802463Z",
     "iopub.status.busy": "2024-09-26T16:53:19.802184Z",
     "iopub.status.idle": "2024-09-26T16:53:19.811304Z",
     "shell.execute_reply": "2024-09-26T16:53:19.810735Z"
    },
    "id": "NgbN4RY8I0vM",
    "outputId": "3d33bcca-fa00-4df7-a038-1fbbae34bab9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>given_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>89.00</td>\n",
       "      <td>95.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>64.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>53.00</td>\n",
       "      <td>89.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>77.00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     exam_1  exam_2  exam_3 notes given_label predicted_label\n",
       "3      0.61    0.94    0.78   NaN           C               F\n",
       "886   89.00   95.00   73.00   NaN           D               B\n",
       "709   64.00   70.00   86.00   NaN           F               C\n",
       "723   53.00   89.00   78.00   NaN           A               C\n",
       "689   77.00   51.00   70.00   NaN           B               D"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_issues = issue_results.sort_values(\"label_score\").index\n",
    "\n",
    "X_raw.iloc[sorted_issues].assign(\n",
    "    given_label=labels.iloc[sorted_issues],\n",
    "    predicted_label=issue_results[\"predicted_label\"].iloc[sorted_issues]\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w66eSO1lI0vM"
   },
   "source": [
    "The dataframe above shows the original labelÂ (`given_label`) for examples that cleanlab finds most likely to be mislabeled, as well as an alternative `predicted_label` for each example.\n",
    "\n",
    "These examples have been labeled incorrectly and should be carefully re-examined - a student with grades of 89, 95 and 73 surely does not deserve a D!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CD9GuT30I0vM"
   },
   "source": [
    "### Outlier issues\n",
    "\n",
    "According to the report, our dataset contains some outliers. We can see which examples are outliers (and a numeric quality score quantifying how typical each example appears to be) via `get_issues`. We sort the resulting DataFrame by cleanlab's outlier quality score to see the most severe outliers in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:19.813036Z",
     "iopub.status.busy": "2024-09-26T16:53:19.812765Z",
     "iopub.status.idle": "2024-09-26T16:53:19.821318Z",
     "shell.execute_reply": "2024-09-26T16:53:19.820770Z"
    },
    "id": "-_uK40JKI0vM",
    "outputId": "1c6a92e4-5ccc-4e77-b6f9-1d73d11290d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.00</td>\n",
       "      <td>77.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>96.00</td>\n",
       "      <td>&lt;p style=\"font-size: 18px; color: #ff00ff; bac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exam_1  exam_2  exam_3                                              notes\n",
       "3    0.61    0.94    0.78                                                NaN\n",
       "7  100.00  100.00    1.00                                                NaN\n",
       "0   53.00   77.00    9.00                                                  3\n",
       "4   48.00   90.00    9.00                                                  1\n",
       "8    0.00   56.00   96.00  <p style=\"font-size: 18px; color: #ff00ff; bac..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_results = lab.get_issues(\"outlier\")\n",
    "sorted_outliers= outlier_results.sort_values(\"outlier_score\").index\n",
    "\n",
    "X_raw.iloc[sorted_outliers].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff_04ldlI0vN"
   },
   "source": [
    "The student at index 3 has fractional exam scores, which is likely a error. We also see that the students at index 0 and 4 have numerical values in their notes section, which is also probably unintended. Lastly, we see that the student at index 8 has a html string in their notes section, definitely a mistake!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1o7QTtIGI0vN"
   },
   "source": [
    "### Near-duplicate issues\n",
    "\n",
    "According to the report, our dataset contains some sets of nearly duplicated examples.\n",
    "We can see which examples are (nearly) duplicated (and a numeric quality score quantifying how dissimilar each example is from its nearest neighbor in the dataset) via `get_issues`. We sort the resulting DataFrame by cleanlab's near-duplicate quality score to see the examples in our dataset that are most nearly duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:19.823132Z",
     "iopub.status.busy": "2024-09-26T16:53:19.822844Z",
     "iopub.status.idle": "2024-09-26T16:53:19.832173Z",
     "shell.execute_reply": "2024-09-26T16:53:19.831632Z"
    },
    "id": "SHTQR-NPI0vN",
    "outputId": "7983aea0-33f0-454b-e031-98b17dca2d49"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_near_duplicate_issue</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_sets</th>\n",
       "      <th>distance_to_nearest_neighbor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[246]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[582]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[294]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[915]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[27]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  \\\n",
       "690                     True                   0.0               [246]   \n",
       "185                     True                   0.0               [582]   \n",
       "691                     True                   0.0               [294]   \n",
       "168                     True                   0.0               [915]   \n",
       "187                     True                   0.0                [27]   \n",
       "\n",
       "     distance_to_nearest_neighbor  \n",
       "690                           0.0  \n",
       "185                           0.0  \n",
       "691                           0.0  \n",
       "168                           0.0  \n",
       "187                           0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_results = lab.get_issues(\"near_duplicate\")\n",
    "duplicate_results.sort_values(\"near_duplicate_score\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_near_duplicate_issue</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_sets</th>\n",
       "      <th>distance_to_nearest_neighbor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[12, 2, 6, 9]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[12, 1, 6, 9]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[12, 2, 1, 9]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[12, 2, 1, 6]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2, 1, 6, 9]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[187]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[915]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[582]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[27]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[690]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[691]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[185]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[898]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[246]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[294]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[637]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[168]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  \\\n",
       "1                       True                   0.0       [12, 2, 6, 9]   \n",
       "2                       True                   0.0       [12, 1, 6, 9]   \n",
       "6                       True                   0.0       [12, 2, 1, 9]   \n",
       "9                       True                   0.0       [12, 2, 1, 6]   \n",
       "12                      True                   0.0        [2, 1, 6, 9]   \n",
       "27                      True                   0.0               [187]   \n",
       "168                     True                   0.0               [915]   \n",
       "185                     True                   0.0               [582]   \n",
       "187                     True                   0.0                [27]   \n",
       "246                     True                   0.0               [690]   \n",
       "294                     True                   0.0               [691]   \n",
       "582                     True                   0.0               [185]   \n",
       "637                     True                   0.0               [898]   \n",
       "690                     True                   0.0               [246]   \n",
       "691                     True                   0.0               [294]   \n",
       "898                     True                   0.0               [637]   \n",
       "915                     True                   0.0               [168]   \n",
       "\n",
       "     distance_to_nearest_neighbor  \n",
       "1                             0.0  \n",
       "2                             0.0  \n",
       "6                             0.0  \n",
       "9                             0.0  \n",
       "12                            0.0  \n",
       "27                            0.0  \n",
       "168                           0.0  \n",
       "185                           0.0  \n",
       "187                           0.0  \n",
       "246                           0.0  \n",
       "294                           0.0  \n",
       "582                           0.0  \n",
       "637                           0.0  \n",
       "690                           0.0  \n",
       "691                           0.0  \n",
       "898                           0.0  \n",
       "915                           0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_results[duplicate_results['is_near_duplicate_issue'] == True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0UUgz83I0vN"
   },
   "source": [
    "The results above show which examples cleanlab considers nearly duplicated (rows where `is_near_duplicate_issue == True`). Here, we see some examples that cleanlab has flagged as being nearly duplicated. Let's view these examples to see how similar they are\n",
    "\n",
    "Using the one of the lowest-scoring examples, let's compare it against the identified near-duplicate sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:19.833892Z",
     "iopub.status.busy": "2024-09-26T16:53:19.833586Z",
     "iopub.status.idle": "2024-09-26T16:53:19.840886Z",
     "shell.execute_reply": "2024-09-26T16:53:19.840344Z"
    },
    "id": "G6gyiZ2UI0vN",
    "outputId": "ddc3f561-b0b6-4a86-a032-b058addd81f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>great participation +10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>81.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>great participation +10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>great participation +10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>81.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>great participation +10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>81.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>great participation +10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    exam_1  exam_2  exam_3                    notes\n",
       "1     81.0    64.0    80.0  great participation +10\n",
       "12    81.0    64.0    80.0  great participation +10\n",
       "2     81.0    64.0    80.0  great participation +10\n",
       "6     81.0    64.0    80.0  great participation +10\n",
       "9     81.0    64.0    80.0  great participation +10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the row with the lowest near_duplicate_score\n",
    "lowest_scoring_duplicate = duplicate_results[\"near_duplicate_score\"].idxmin()\n",
    "\n",
    "# Extract the indices of the lowest scoring duplicate and its near duplicate sets\n",
    "indices_to_display = [lowest_scoring_duplicate] + duplicate_results.loc[lowest_scoring_duplicate, \"near_duplicate_sets\"].tolist()\n",
    "\n",
    "# Display the relevant rows from the original dataset\n",
    "X_raw.iloc[indices_to_display]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1t2dEmQI0vO"
   },
   "source": [
    "These examples are exact duplicates! Perhaps the same information was accidentally recorded multiple times in this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTGDUNlgI0vS"
   },
   "source": [
    "Similarly, let's take a look at another example and the identified near-duplicate sets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:19.842748Z",
     "iopub.status.busy": "2024-09-26T16:53:19.842418Z",
     "iopub.status.idle": "2024-09-26T16:53:19.849893Z",
     "shell.execute_reply": "2024-09-26T16:53:19.849349Z"
    },
    "id": "QrXlfIlcI0vS",
    "outputId": "3a3a1680-582b-4cb9-f7b0-c3807840073a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>86.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>86.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     exam_1  exam_2  exam_3 notes\n",
       "27     86.0    80.0    89.0   NaN\n",
       "187    86.0    80.0    89.0   NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the next row not in the previous near duplicate set\n",
    "second_lowest_scoring_duplicate = duplicate_results[\"near_duplicate_score\"].drop(indices_to_display).idxmin()\n",
    "\n",
    "# Extract the indices of the second lowest scoring duplicate and its near duplicate sets\n",
    "next_indices_to_display = [second_lowest_scoring_duplicate] + duplicate_results.loc[second_lowest_scoring_duplicate, \"near_duplicate_sets\"].tolist()\n",
    "\n",
    "# Display the relevant rows from the original dataset\n",
    "X_raw.iloc[next_indices_to_display]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AOYNVS1I0vS"
   },
   "source": [
    "We identified another set of exact duplicates in our dataset! Including near/exact duplicates in a dataset may have unintended effects on models; be wary about splitting them across training/test sets. Learn more about handling near duplicates detected in a dataset from [the FAQ](../faq.html#How-to-handle-near-duplicate-data-identified-by-cleanlab?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUg0fDyoI0vS"
   },
   "source": [
    "This tutorial highlighted a straightforward approach to detect potentially incorrect information in any tabular dataset. Just use Datalab with any ML model -- the better the model, the more accurate the data errors detected by Datalab will be!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vjq4-sC9I0vT"
   },
   "source": [
    "## Spending too much time on data quality?\n",
    "\n",
    "Using this open-source package effectively can require significant ML expertise and experimentation, plus handling detected data issues can be cumbersome.\n",
    "\n",
    "Thatâs why we built [Cleanlab Studio](https://cleanlab.ai/blog/data-centric-ai/) -- an automated platform to findÂ **and fix**Â issues in your dataset, 100x faster and more accurately.  Cleanlab Studio automatically runs optimized data quality algorithms from this package on top of cutting-edge AutoML & Foundation models fit to your data, and helps you fix detected issues via a smart data correction interface. [Try it](https://cleanlab.ai/)Â for free!\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/ml-with-cleanlab-studio.png\" alt=\"The modern AI pipeline automated with Cleanlab Studio\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T16:53:19.851833Z",
     "iopub.status.busy": "2024-09-26T16:53:19.851517Z",
     "iopub.status.idle": "2024-09-26T16:53:19.860008Z",
     "shell.execute_reply": "2024-09-26T16:53:19.859548Z"
    },
    "id": "FsYBq7sPI0vT",
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Note: This cell is only for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "identified_label_issues = issue_results[issue_results[\"is_label_issue\"] == True]\n",
    "label_issue_indices = [3, 723, 709, 886, 689]  # check these examples were found in label issues\n",
    "if not all(x in identified_label_issues.index for x in label_issue_indices):\n",
    "    raise Exception(\"Some highlighted examples are missing from identified_label_issues.\")\n",
    "\n",
    "identified_outlier_issues = outlier_results[outlier_results[\"is_outlier_issue\"] == True]\n",
    "outlier_issue_indices = [3, 7, 0, 4, 8]  # check these examples were found in outlier issues\n",
    "if not all(x in identified_outlier_issues.index for x in outlier_issue_indices):\n",
    "    raise Exception(\"Some highlighted examples are missing from identified_outlier_issues.\")\n",
    "\n",
    "identified_duplicate_issues = duplicate_results[duplicate_results[\"is_near_duplicate_issue\"] == True]\n",
    "duplicate_issue_indices = [690, 246, 185, 582]  # check these examples were found in duplicate issues\n",
    "if not all(x in identified_duplicate_issues.index for x in duplicate_issue_indices):\n",
    "    raise Exception(\"Some highlighted examples are missing from identified_duplicate_issues.\")\n",
    "\n",
    "# check that the near duplicates shown are actually flagged as near duplicate sets\n",
    "if not duplicate_results.iloc[690][\"near_duplicate_sets\"] == 246:\n",
    "    raise Exception(\"These examples are not in the same near duplicate set\")\n",
    "\n",
    "if not duplicate_results.iloc[185][\"near_duplicate_sets\"] == 582:\n",
    "    raise Exception(\"These examples are not in the same near duplicate set\")\n",
    "\n",
    "# Function to check if all rows are identical\n",
    "def are_rows_identical(df):\n",
    "    first_row = df.iloc[0]\n",
    "    return all(df.iloc[i].equals(first_row) for i in range(1, len(df)))\n",
    "\n",
    "# Test to ensure all displayed rows are identical\n",
    "if not are_rows_identical(X_raw.iloc[indices_to_display]):\n",
    "    raise Exception(\"Not all rows are identical! These examples should belong to the same EXACT duplicate set\")\n",
    "\n",
    "# Repeat the test for the next set of indices\n",
    "if not are_rows_identical(X_raw.iloc[next_indices_to_display]):\n",
    "    raise Exception(\"Not all rows are identical! These examples should belong to the same EXACT duplicate set\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
